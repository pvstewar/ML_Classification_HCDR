{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3- Feature and ML Pipelines\n",
    "\n",
    "Created by Michael Casey, Andrew Cruez, Peter Stewart, and Hemraj Yadav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__About Part 3__\n",
    "In this part we will look at the Scikit-learn module and after pre-processing the dataset, we will run multiple experiments, changing the hyperparameters to determeine our best model for creating our submission file to test our data in the Kaggle competiion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our modules and settings and loading our data from part 1 and 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB, ComplementNB\n",
    "from time import time\n",
    "import featuretools as ft\n",
    "import warnings\n",
    "import pickle\n",
    "import woodwork as ww\n",
    "from scipy.stats import t\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data from part I\n",
    "DATA_DIR = \"./Data/home-credit-default-risk\"\n",
    "\n",
    "with open(f\"{DATA_DIR}/datasets.pkl\", 'rb') as n:\n",
    "    datasets = pickle.load(n)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_train_FT.pkl\", 'rb') as r:\n",
    "    X_train_FT = pickle.load(r)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_test_FT.pkl\", 'rb') as e:\n",
    "    X_test_FT = pickle.load(e)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_train_MF.pkl\", 'rb') as mr:\n",
    "    X_train_MF = pickle.load(mr)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_test_MF.pkl\", 'rb') as me:\n",
    "    X_test_MF = pickle.load(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KD32ABWVV2u3",
    "outputId": "da778a1e-6cc7-4bb5-aab7-46eee3d53a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['COUNT(bureau_balance_FT)', 'COUNT(cash_FT)', 'COUNT(credit_FT)',\n",
       "       'COUNT(installments_FT)', 'COUNT(previous_FT)',\n",
       "       'MAX(bureau_FT.AMT_ANNUITY)', 'MAX(bureau_FT.AMT_CREDIT_MAX_OVERDUE)',\n",
       "       'MAX(bureau_FT.AMT_CREDIT_SUM)', 'MAX(bureau_FT.AMT_CREDIT_SUM_DEBT)',\n",
       "       'MAX(bureau_FT.AMT_CREDIT_SUM_LIMIT)',\n",
       "       ...\n",
       "       'SUM(previous_FT.DAYS_LAST_DUE)',\n",
       "       'SUM(previous_FT.DAYS_LAST_DUE_1ST_VERSION)',\n",
       "       'SUM(previous_FT.DAYS_TERMINATION)',\n",
       "       'SUM(previous_FT.HOUR_APPR_PROCESS_START)',\n",
       "       'SUM(previous_FT.NFLAG_INSURED_ON_APPROVAL)',\n",
       "       'SUM(previous_FT.NFLAG_LAST_APPL_IN_DAY)',\n",
       "       'SUM(previous_FT.RATE_DOWN_PAYMENT)',\n",
       "       'SUM(previous_FT.RATE_INTEREST_PRIMARY)',\n",
       "       'SUM(previous_FT.RATE_INTEREST_PRIVILEGED)',\n",
       "       'SUM(previous_FT.SELLERPLACE_AREA)'],\n",
       "      dtype='object', length=1080)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get rid of duplicate columns (basically the original data cols)\n",
    "kp_list = (X_train_FT.columns.difference(X_train_MF.columns))\n",
    "print(len(kp_list))\n",
    "kp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We should get a matching number and empty list below proving that test and train FT sets have same cols.\n",
    "kp_list_tst = (X_test_FT.columns.difference(X_test_MF.columns))\n",
    "print(len(kp_list))\n",
    "print(kp_list_tst.difference(kp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLJt4b2vV2u3",
    "outputId": "a4df48c0-dd34-4b45-d609-ac462d2e5955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1299)\n"
     ]
    }
   ],
   "source": [
    "# combine train datasets for ML train set\n",
    "X_train = X_train_MF.merge(X_train_FT[kp_list], left_index=True, right_index=True, how='outer')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G451Q8aTV2u3",
    "outputId": "3481a4ba-d271-4653-808b-dbef752413ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 1298)\n"
     ]
    }
   ],
   "source": [
    "# This will be our \"Set-Aside\" copy since this test set doesn't contain tagets we can't use to train the model, only to submit for Kaggle score.\n",
    "X_test_SA = X_test_MF.merge(X_test_FT[kp_list], left_index=True, right_index=True, how='outer')\n",
    "print(X_test_SA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1298)\n",
      "(48744, 1297)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop('SK_ID_CURR', axis=1, inplace=True)\n",
    "print(X_train.shape)\n",
    "X_test_SA.drop('SK_ID_CURR', axis=1, inplace=True)\n",
    "print(X_test_SA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the preprocessing pipelines for our data\n",
    "BL_num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "BL_cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "MNB_num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant',fill_value= 0)),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "    ])\n",
    "\n",
    "new_num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant',fill_value= 0)),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1297)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>SUM(previous_FT.DAYS_LAST_DUE)</th>\n",
       "      <th>SUM(previous_FT.DAYS_LAST_DUE_1ST_VERSION)</th>\n",
       "      <th>SUM(previous_FT.DAYS_TERMINATION)</th>\n",
       "      <th>SUM(previous_FT.HOUR_APPR_PROCESS_START)</th>\n",
       "      <th>SUM(previous_FT.NFLAG_INSURED_ON_APPROVAL)</th>\n",
       "      <th>SUM(previous_FT.NFLAG_LAST_APPL_IN_DAY)</th>\n",
       "      <th>SUM(previous_FT.RATE_DOWN_PAYMENT)</th>\n",
       "      <th>SUM(previous_FT.RATE_INTEREST_PRIMARY)</th>\n",
       "      <th>SUM(previous_FT.RATE_INTEREST_PRIVILEGED)</th>\n",
       "      <th>SUM(previous_FT.SELLERPLACE_AREA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-17.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>...</td>\n",
       "      <td>-3163.0</td>\n",
       "      <td>-3013.0</td>\n",
       "      <td>-3142.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.150091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>-724.0</td>\n",
       "      <td>-694.0</td>\n",
       "      <td>-714.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>1642297.5</td>\n",
       "      <td>824256.0</td>\n",
       "      <td>1642335.75</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.470709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>432817.2</td>\n",
       "      <td>-5023.2</td>\n",
       "      <td>432862.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.957098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2455.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0         Cash loans           M            N               Y             0   \n",
       "1         Cash loans           F            N               N             0   \n",
       "2    Revolving loans           M            Y               Y             0   \n",
       "3         Cash loans           F            N               Y             0   \n",
       "4         Cash loans           M            N               Y             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE NAME_TYPE_SUITE  \\\n",
       "0          202500.0    406597.5      24700.5         351000.0   Unaccompanied   \n",
       "1          270000.0   1293502.5      35698.5        1129500.0          Family   \n",
       "2           67500.0    135000.0       6750.0         135000.0   Unaccompanied   \n",
       "3          135000.0    312682.5      29686.5         297000.0   Unaccompanied   \n",
       "4          121500.0    513000.0      21865.5         513000.0   Unaccompanied   \n",
       "\n",
       "   ... SUM(previous_FT.DAYS_LAST_DUE)  \\\n",
       "0  ...                          -25.0   \n",
       "1  ...                        -3163.0   \n",
       "2  ...                         -724.0   \n",
       "3  ...                      1642297.5   \n",
       "4  ...                       432817.2   \n",
       "\n",
       "  SUM(previous_FT.DAYS_LAST_DUE_1ST_VERSION)  \\\n",
       "0                                      125.0   \n",
       "1                                    -3013.0   \n",
       "2                                     -694.0   \n",
       "3                                   824256.0   \n",
       "4                                    -5023.2   \n",
       "\n",
       "  SUM(previous_FT.DAYS_TERMINATION) SUM(previous_FT.HOUR_APPR_PROCESS_START)  \\\n",
       "0                            -17.00                                      9.0   \n",
       "1                          -3142.00                                     44.0   \n",
       "2                           -714.00                                      5.0   \n",
       "3                        1642335.75                                    132.0   \n",
       "4                         432862.80                                     74.0   \n",
       "\n",
       "   SUM(previous_FT.NFLAG_INSURED_ON_APPROVAL)  \\\n",
       "0                                         0.0   \n",
       "1                                         2.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         3.6   \n",
       "\n",
       "   SUM(previous_FT.NFLAG_LAST_APPL_IN_DAY)  \\\n",
       "0                                      1.0   \n",
       "1                                      3.0   \n",
       "2                                      1.0   \n",
       "3                                      9.0   \n",
       "4                                      6.0   \n",
       "\n",
       "   SUM(previous_FT.RATE_DOWN_PAYMENT)  SUM(previous_FT.RATE_INTEREST_PRIMARY)  \\\n",
       "0                            0.000000                                     0.0   \n",
       "1                            0.150091                                     0.0   \n",
       "2                            0.212008                                     0.0   \n",
       "3                            1.470709                                     0.0   \n",
       "4                            0.957098                                     0.0   \n",
       "\n",
       "   SUM(previous_FT.RATE_INTEREST_PRIVILEGED)  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   SUM(previous_FT.SELLERPLACE_AREA)  \n",
       "0                              500.0  \n",
       "1                             1599.0  \n",
       "2                               30.0  \n",
       "3                             8048.0  \n",
       "4                             2455.0  \n",
       "\n",
       "[5 rows x 1297 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split out the target column to creat y values\n",
    "y_train = X_train['TARGET']\n",
    "X_train = X_train.loc[:, ~X_train.columns.isin(['TARGET'])]\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train test and valid sets from X and Y train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's determine which features are categorical or numerical for our X_train_FT dataset\n",
    "numerical_at = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_at = X_train.select_dtypes(include=['object', 'bool']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297\n",
      "1297\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 209107 entries, 35339 to 212146\n",
      "Columns: 1297 entries, NAME_CONTRACT_TYPE to SUM(previous_FT.SELLERPLACE_AREA)\n",
      "dtypes: float64(1233), int64(44), object(20)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# check to make sure our cat/num lists have all the columns from original dataset\n",
    "# make sure all categorical data is string type\n",
    "X_train[categorical_at]=X_train[categorical_at].astype(str)\n",
    "tot_from_above = (len(numerical_at)+len(categorical_at))\n",
    "print (X_train.shape[1])\n",
    "print (tot_from_above)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>EMERGENCYSTATE_MODE_nan</th>\n",
       "      <th>ApprovedorRejected_x_0</th>\n",
       "      <th>ApprovedorRejected_x_Approved</th>\n",
       "      <th>ApprovedorRejected_y_0</th>\n",
       "      <th>ApprovedorRejected_y_Refused</th>\n",
       "      <th>ACTIVE_CLOSED_SUM_BUREAU_x_0</th>\n",
       "      <th>ACTIVE_CLOSED_SUM_BUREAU_x_ACTIVE</th>\n",
       "      <th>ACTIVE_CLOSED_SUM_BUREAU_y_0</th>\n",
       "      <th>ACTIVE_CLOSED_SUM_BUREAU_y_CLOSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.113535</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.282797</td>\n",
       "      <td>0.797238</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.791168</td>\n",
       "      <td>0.684313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>0.428742</td>\n",
       "      <td>0.180139</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.336758</td>\n",
       "      <td>0.689684</td>\n",
       "      <td>0.037863</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.440461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>0.044124</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.136490</td>\n",
       "      <td>0.064713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487573</td>\n",
       "      <td>0.395026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.053995</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.421848</td>\n",
       "      <td>0.365953</td>\n",
       "      <td>0.033240</td>\n",
       "      <td>0.663862</td>\n",
       "      <td>0.684452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.333611</td>\n",
       "      <td>0.147701</td>\n",
       "      <td>0.297778</td>\n",
       "      <td>0.421848</td>\n",
       "      <td>0.913078</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>0.835625</td>\n",
       "      <td>0.791719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0      0.105263          0.008783    0.123596     0.113535         0.133333   \n",
       "1      0.052632          0.014795    0.428742     0.180139         0.388889   \n",
       "2      0.000000          0.008115    0.029146     0.044124         0.033333   \n",
       "3      0.000000          0.003106    0.056180     0.053995         0.066667   \n",
       "4      0.000000          0.013125    0.333611     0.147701         0.297778   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                    0.282797    0.797238       0.038258           0.791168   \n",
       "1                    0.336758    0.689684       0.037863           0.928852   \n",
       "2                    0.136490    0.064713       1.000000           0.487573   \n",
       "3                    0.421848    0.365953       0.033240           0.663862   \n",
       "4                    0.421848    0.913078       0.042066           0.835625   \n",
       "\n",
       "   DAYS_ID_PUBLISH  ...  EMERGENCYSTATE_MODE_Yes  EMERGENCYSTATE_MODE_nan  \\\n",
       "0         0.684313  ...                      0.0                      0.0   \n",
       "1         0.440461  ...                      0.0                      1.0   \n",
       "2         0.395026  ...                      0.0                      0.0   \n",
       "3         0.684452  ...                      0.0                      1.0   \n",
       "4         0.791719  ...                      0.0                      1.0   \n",
       "\n",
       "   ApprovedorRejected_x_0  ApprovedorRejected_x_Approved  \\\n",
       "0                     0.0                            1.0   \n",
       "1                     0.0                            1.0   \n",
       "2                     0.0                            1.0   \n",
       "3                     0.0                            1.0   \n",
       "4                     1.0                            0.0   \n",
       "\n",
       "   ApprovedorRejected_y_0  ApprovedorRejected_y_Refused  \\\n",
       "0                     1.0                           0.0   \n",
       "1                     0.0                           1.0   \n",
       "2                     0.0                           1.0   \n",
       "3                     1.0                           0.0   \n",
       "4                     1.0                           0.0   \n",
       "\n",
       "   ACTIVE_CLOSED_SUM_BUREAU_x_0  ACTIVE_CLOSED_SUM_BUREAU_x_ACTIVE  \\\n",
       "0                           0.0                                1.0   \n",
       "1                           1.0                                0.0   \n",
       "2                           0.0                                1.0   \n",
       "3                           1.0                                0.0   \n",
       "4                           0.0                                1.0   \n",
       "\n",
       "   ACTIVE_CLOSED_SUM_BUREAU_y_0  ACTIVE_CLOSED_SUM_BUREAU_y_CLOSED  \n",
       "0                           0.0                                1.0  \n",
       "1                           1.0                                0.0  \n",
       "2                           0.0                                1.0  \n",
       "3                           1.0                                0.0  \n",
       "4                           0.0                                1.0  \n",
       "\n",
       "[5 rows x 1431 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run our X_train through the column transformer to store the input number and check the output\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "       (\"num_pipeline\", new_num_pipeline, numerical_at),\n",
    "       (\"cat_pipeline\", BL_cat_pipeline, categorical_at)],\n",
    "       remainder='drop',\n",
    "        n_jobs=1\n",
    "   )\n",
    "\n",
    "X_train_transformed = data_pipeline.fit_transform(X_train)\n",
    "\n",
    "column_names = list(numerical_at) + list(data_pipeline.transformers_[1][1].named_steps[\"ohe\"].get_feature_names(categorical_at))\n",
    "# print(column_names)\n",
    "display(pd.DataFrame(X_train_transformed,  columns=column_names).head())\n",
    "number_of_inputs = X_train_transformed.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Experiment Pipeline\n",
    "\n",
    "The next section of the notebook is the model and experiment pipeline which is where we will run our data through a series of experiments with multilayer perceptron, binomial logistic regression, and multinomial naïve bayes algorithms. We will select our best model from these options to submit for scoring on Kaggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perceptron Loss Function:**\n",
    "$${\\displaystyle {\\frac {1} {m}} \\sum _{i=1}^{M} {Max}(0,−X^T_i*W*y_i) }$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best score: 0.725\n",
      "Best parameters set:\n",
      "\tMLPC__activation: 'relu'\n",
      "\tMLPC__solver: 'lbfgs'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Test Accuracy\n",
       "0  MLPClassifier          0.758"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First doing a gridsearch for best params for MLPClassifer\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('feat_sel', SelectKBest(chi2, k=50)),\n",
    "        ('MLPC', MLPClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'MLPC__activation': ('logistic', 'relu'),\n",
    "    'MLPC__solver': ('lbfgs', 'sgd', 'adam'),\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, scoring='roc_auc' ,cv=3, n_jobs=1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "preds = grid_search.predict_proba(X_train)\n",
    "accuracy = roc_auc_score(y_train, preds[:,1])\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Test Accuracy\"])\n",
    "results.loc[len(results)] = [\"MLPClassifier\", np.round(accuracy, 3)]\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our gridsearch found the best parameters to be activation = relu and solver = lbfgs. Now we'll use those values to run some experiments. We are going to play with the values of K first, this will determine how many features we will use in the model with the chi squared method as the selector. Our first experiment is k = 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.85056</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline    RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.85056     92.09%     91.81%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "\n",
       "                           Description  \n",
       "0  MLPClassifier pipeline with K = 200  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('feat_sel', SelectKBest(chi2, k=200)),\n",
    "        ('MLP', MLPClassifier(activation= 'relu', solver = 'lbfgs', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClassifier pipeline with K = 200\",]\n",
    "\n",
    "experimentLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.85056</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.13610</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline    RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.85056     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.13610     91.99%     91.94%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "\n",
       "                           Description  \n",
       "0  MLPClassifier pipeline with K = 200  \n",
       "1  MLPClassifier pipeline with K = 100  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try an experiment with k values 100 on the selector\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('feat_sel', SelectKBest(chi2, k=100)),\n",
    "        ('MLP', MLPClassifier(activation= 'logistic', solver = 'sgd', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClassifier pipeline with K = 100\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "\n",
       "                            Description  \n",
       "0   MLPClassifier pipeline with K = 200  \n",
       "1   MLPClassifier pipeline with K = 100  \n",
       "2  MLPClassifier pipeline with  K = 300  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see a little difference between 100 and 200 so let's try 300\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('feat_sel', SelectKBest(chi2, k=300)),\n",
    "        ('MLP', MLPClassifier(activation= 'relu', solver = 'lbfgs', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"ValidAuc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClassifier pipeline with  K = 300\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our first 3 experiments we find that as we increase the value of K we have longer processing times and increases in accuracy of less than 1% per 100 K increase. Next we will do some experimentation with PCA which will reduce the dimensions of our data based on the value that we enter for the component count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "\n",
       "                               Description  \n",
       "0      MLPClassifier pipeline with K = 200  \n",
       "1      MLPClassifier pipeline with K = 100  \n",
       "2     MLPClassifier pipeline with  K = 300  \n",
       "3  MLPClassifier pipeline with PCA 50 comp  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's run an experiment with PCA set to create 50 compnents.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=50)),\n",
    "        ('MLP', MLPClassifier(activation= 'relu', solver = 'lbfgs', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClassifier pipeline with PCA 50 comp\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "4  Baseline MLPClassifier with 1431 inputs  114.665470     92.76%     89.84%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "4        89.61%     86.30%     68.73%     69.08%   \n",
       "\n",
       "                                Description  \n",
       "0       MLPClassifier pipeline with K = 200  \n",
       "1       MLPClassifier pipeline with K = 100  \n",
       "2      MLPClassifier pipeline with  K = 300  \n",
       "3   MLPClassifier pipeline with PCA 50 comp  \n",
       "4  MLPClassifier pipeline with PCA 150 comp  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's run an experiment with PCA creating 150 dimensions based on our data\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=150)),\n",
    "        ('MLP', MLPClassifier(activation= 'relu', solver = 'lbfgs', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClassifier pipeline with PCA 150 comp\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "4  Baseline MLPClassifier with 1431 inputs  114.665470     92.76%     89.84%   \n",
       "5  Baseline MLPClassifier with 1431 inputs  118.564886     93.09%     89.20%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "4        89.61%     86.30%     68.73%     69.08%   \n",
       "5        89.01%     88.04%     68.68%     69.90%   \n",
       "\n",
       "                                   Description  \n",
       "0          MLPClassifier pipeline with K = 200  \n",
       "1          MLPClassifier pipeline with K = 100  \n",
       "2         MLPClassifier pipeline with  K = 300  \n",
       "3      MLPClassifier pipeline with PCA 50 comp  \n",
       "4     MLPClassifier pipeline with PCA 150 comp  \n",
       "5  MLPClassifier pipeline with PCA of 250 comp  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's run an experiment with PCA creating 250 dimensions based on our data\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=250)),\n",
    "        ('MLP', MLPClassifier(activation= 'relu', solver = 'lbfgs', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClassifier pipeline with PCA of 250 comp\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running several PCA values for our model we see that the best overall AUC score is achieved with 250 components but this was only a small increase over 150 components which in turn was a larger increase over 50 components. For our final experiment with MLP let’s try running without trimming the features or dimension reduction and see how the score does with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "4  Baseline MLPClassifier with 1431 inputs  114.665470     92.76%     89.84%   \n",
       "5  Baseline MLPClassifier with 1431 inputs  118.564886     93.09%     89.20%   \n",
       "6  Baseline MLPClassifier with 1431 inputs  294.561357     92.00%     91.91%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "4        89.61%     86.30%     68.73%     69.08%   \n",
       "5        89.01%     88.04%     68.68%     69.90%   \n",
       "6        91.67%     74.56%     74.84%     74.84%   \n",
       "\n",
       "                                   Description  \n",
       "0          MLPClassifier pipeline with K = 200  \n",
       "1          MLPClassifier pipeline with K = 100  \n",
       "2         MLPClassifier pipeline with  K = 300  \n",
       "3      MLPClassifier pipeline with PCA 50 comp  \n",
       "4     MLPClassifier pipeline with PCA 150 comp  \n",
       "5  MLPClassifier pipeline with PCA of 250 comp  \n",
       "6       MLPClass pipeline full data, log, relu  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's run an experiment with PCA creating 250 dimensions based on our data\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('MLP', MLPClassifier(activation= 'logistic', solver = 'sgd', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClass pipeline full data, log, sgd\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "4  Baseline MLPClassifier with 1431 inputs  114.665470     92.76%     89.84%   \n",
       "5  Baseline MLPClassifier with 1431 inputs  118.564886     93.09%     89.20%   \n",
       "6  Baseline MLPClassifier with 1431 inputs  294.561357     92.00%     91.91%   \n",
       "7  Baseline MLPClassifier with 1431 inputs  273.255891     92.06%     91.94%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "4        89.61%     86.30%     68.73%     69.08%   \n",
       "5        89.01%     88.04%     68.68%     69.90%   \n",
       "6        91.67%     74.56%     74.84%     74.84%   \n",
       "7        91.65%     77.34%     75.76%     75.92%   \n",
       "\n",
       "                                   Description  \n",
       "0          MLPClassifier pipeline with K = 200  \n",
       "1          MLPClassifier pipeline with K = 100  \n",
       "2         MLPClassifier pipeline with  K = 300  \n",
       "3      MLPClassifier pipeline with PCA 50 comp  \n",
       "4     MLPClassifier pipeline with PCA 150 comp  \n",
       "5  MLPClassifier pipeline with PCA of 250 comp  \n",
       "6       MLPClass pipeline full data, log, relu  \n",
       "7     MLPClass pipeline full data, relu, lbfgs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('MLP', MLPClassifier(activation= 'relu', solver = 'lbfgs', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\", \"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MLPClassifier with {number_of_inputs} inputs\", run_time ,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"MLPClass pipeline full data, relu, lbfgs\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backing up the data to make it easier to restart the kernel if neccesary\n",
    "\n",
    "with open(f'{DATA_DIR}/X_train.pkl', 'wb') as a:\n",
    "    pickle.dump(X_train, a)\n",
    "\n",
    "with open(f'{DATA_DIR}/X_test.pkl', 'wb') as b:\n",
    "    pickle.dump(X_test, b)\n",
    "\n",
    "with open(f'{DATA_DIR}/y_train.pkl', 'wb') as c:\n",
    "    pickle.dump(y_train, c)\n",
    "\n",
    "with open(f'{DATA_DIR}/y_test.pkl', 'wb') as d:\n",
    "    pickle.dump(y_test, d)\n",
    "\n",
    "with open(f'{DATA_DIR}/X_valid.pkl', 'wb') as e:\n",
    "    pickle.dump(X_valid, e)\n",
    "\n",
    "with open(f'{DATA_DIR}/y_valid.pkl', 'wb') as f:\n",
    "    pickle.dump(y_valid, f)\n",
    "\n",
    "with open(f'{DATA_DIR}/X_test_SA.pkl', 'wb') as g:\n",
    "    pickle.dump(X_test_SA, g)\n",
    "\n",
    "with open(f'{DATA_DIR}/exp_log.pkl', 'wb') as h:\n",
    "    pickle.dump(experimentLog, h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/X_train.pkl\", 'rb') as aa:\n",
    "    X_train = pickle.load(aa)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_test.pkl\", 'rb') as bb:\n",
    "    X_test = pickle.load(bb)\n",
    "\n",
    "with open(f\"{DATA_DIR}/y_train.pkl\", 'rb') as cc:\n",
    "    y_train = pickle.load(cc)\n",
    "\n",
    "with open(f\"{DATA_DIR}/y_test.pkl\", 'rb') as dd:\n",
    "    y_test = pickle.load(dd)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_valid.pkl\", 'rb') as ee:\n",
    "    X_valid = pickle.load(ee)\n",
    "\n",
    "with open(f\"{DATA_DIR}/y_valid.pkl\", 'rb') as ff:\n",
    "    y_valid = pickle.load(ff)\n",
    "\n",
    "with open(f\"{DATA_DIR}/X_test_SA.pkl\", 'rb') as gg:\n",
    "    X_test_SA = pickle.load(gg)\n",
    "\n",
    "with open(f\"{DATA_DIR}/exp_log.pkl\", 'rb') as hh:\n",
    "    experimentLog = pickle.load(hh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial Logistic Regression with Regularization\n",
    "The objective function for the learning a  binomial logistic regression model (log loss) can be stated as follows:\n",
    "\n",
    "\n",
    "<!-- $$\n",
    "\\underset{\\mathbf{\\theta}}{\\operatorname{argmin}}\\left[\\operatorname{CXE}\\right] = \\underset{\\mathbf{\\theta}}{\\operatorname{argmin}} \\left[ -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) \\right]} \\right] $$ -->\n",
    "\n",
    "$$  -\\frac{1}{m}\\sum^m_{i=1}\\left(y_i\\cdot\\:\\log\\:\\left(p_i\\right)\\:+\\:\\left(1-y_i\\right)\\cdot\\log\\left(1-p_i\\right)\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best score: 0.920\n",
      "Best parameters set:\n",
      "\tlogistic__C: 10\n",
      "\tlogistic__penalty: 'l2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Test Accuracy\n",
       "0  logistic          0.748"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part1 build the pipline in gridsearchcv to find the best params\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=150)),\n",
    "        ('logistic', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'logistic__penalty': ('l1', 'l2', 'elasticnet', 'none'),\n",
    "    'logistic__C':[10, 100.0, 1000.0, 10000.0],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, scoring='roc_auc', cv=3, n_jobs=1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "preds = grid_search.predict_proba(X_train)\n",
    "accuracy = roc_auc_score(y_train, preds[:,1])\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Test Accuracy\"])\n",
    "results.loc[len(results)] = [\"logistic\", np.round(accuracy, 3)]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best score: 0.745\n",
      "Best parameters set:\n",
      "\tlogistic__C: 10000.0\n",
      "\tlogistic__solver: 'newton-cg'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Test Accuracy\n",
       "0  logistic          0.747"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part1 build the pipline in gridsearchcv to find the best params\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=150)),\n",
    "        ('logistic', LogisticRegression(penalty='l2', random_state=42))\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'logistic__C':[10, 100.0, 1000.0, 10000.0],\n",
    "    'logistic__solver':('lbfgs', 'liblinear', 'newton-cg')\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, scoring='roc_auc', cv=3, n_jobs=1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "preds = grid_search.predict_proba(X_train)\n",
    "accuracy = roc_auc_score(y_train, preds[:,1])\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Test Accuracy\"])\n",
    "results.loc[len(results)] = [\"logistic\", np.round(accuracy, 3)]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "4  Baseline MLPClassifier with 1431 inputs  114.665470     92.76%     89.84%   \n",
       "5  Baseline MLPClassifier with 1431 inputs  118.564886     93.09%     89.20%   \n",
       "6  Baseline MLPClassifier with 1431 inputs  294.561357     92.00%     91.91%   \n",
       "7  Baseline MLPClassifier with 1431 inputs  273.255891     92.06%     91.94%   \n",
       "8         Baseline LogReg with 1431 inputs   29.191555     92.00%     91.92%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "4        89.61%     86.30%     68.73%     69.08%   \n",
       "5        89.01%     88.04%     68.68%     69.90%   \n",
       "6        91.67%     74.56%     74.84%     74.84%   \n",
       "7        91.65%     77.34%     75.76%     75.92%   \n",
       "8        91.68%     74.79%     74.86%     74.79%   \n",
       "\n",
       "                                    Description  \n",
       "0           MLPClassifier pipeline with K = 200  \n",
       "1           MLPClassifier pipeline with K = 100  \n",
       "2          MLPClassifier pipeline with  K = 300  \n",
       "3       MLPClassifier pipeline with PCA 50 comp  \n",
       "4      MLPClassifier pipeline with PCA 150 comp  \n",
       "5   MLPClassifier pipeline with PCA of 250 comp  \n",
       "6        MLPClass pipeline full data, log, relu  \n",
       "7      MLPClass pipeline full data, relu, lbfgs  \n",
       "8  logistic regression with c:10000 and PCA 150  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for this experiment let's go with 10000 for C, and PCA 150\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=150)),\n",
    "        ('logistic', LogisticRegression(penalty='l2', C  = 10000.0, solver='newton-cg'))\n",
    "])\n",
    "# Time and score test predictions\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test) [:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train) [:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline LogReg with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"logistic regression with c:10000 and PCA 150\",]\n",
    "\n",
    "experimentLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>28.218472</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.74%</td>\n",
       "      <td>74.75%</td>\n",
       "      <td>74.78%</td>\n",
       "      <td>logistic regression with c:10 and PCA 150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pipeline     RunTime   TrainAcc    TestAcc  \\\n",
       "0  Baseline MLPClassifier with 1431 inputs  107.850560     92.09%     91.81%   \n",
       "1  Baseline MLPClassifier with 1431 inputs   55.136100     91.99%     91.94%   \n",
       "2  Baseline MLPClassifier with 1431 inputs  114.054762     92.16%     91.61%   \n",
       "3  Baseline MLPClassifier with 1431 inputs   89.093591     92.12%     86.99%   \n",
       "4  Baseline MLPClassifier with 1431 inputs  114.665470     92.76%     89.84%   \n",
       "5  Baseline MLPClassifier with 1431 inputs  118.564886     93.09%     89.20%   \n",
       "6  Baseline MLPClassifier with 1431 inputs  294.561357     92.00%     91.91%   \n",
       "7  Baseline MLPClassifier with 1431 inputs  273.255891     92.06%     91.94%   \n",
       "8         Baseline LogReg with 1431 inputs   29.191555     92.00%     91.92%   \n",
       "9         Baseline LogReg with 1431 inputs   28.218472     92.00%     91.91%   \n",
       "\n",
       "  ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0        91.58%     78.08%     72.89%     73.00%   \n",
       "1        91.64%     72.09%     72.59%     72.77%   \n",
       "2        91.35%     79.37%     73.33%     73.60%   \n",
       "3        86.44%     78.87%     65.77%     65.59%   \n",
       "4        89.61%     86.30%     68.73%     69.08%   \n",
       "5        89.01%     88.04%     68.68%     69.90%   \n",
       "6        91.67%     74.56%     74.84%     74.84%   \n",
       "7        91.65%     77.34%     75.76%     75.92%   \n",
       "8        91.68%     74.79%     74.86%     74.79%   \n",
       "9        91.67%     74.74%     74.75%     74.78%   \n",
       "\n",
       "                                    Description  \n",
       "0           MLPClassifier pipeline with K = 200  \n",
       "1           MLPClassifier pipeline with K = 100  \n",
       "2          MLPClassifier pipeline with  K = 300  \n",
       "3       MLPClassifier pipeline with PCA 50 comp  \n",
       "4      MLPClassifier pipeline with PCA 150 comp  \n",
       "5   MLPClassifier pipeline with PCA of 250 comp  \n",
       "6        MLPClass pipeline full data, log, relu  \n",
       "7      MLPClass pipeline full data, relu, lbfgs  \n",
       "8  logistic regression with c:10000 and PCA 150  \n",
       "9     logistic regression with c:10 and PCA 150  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('pca', PCA(n_components=150)),\n",
    "        ('logistic', LogisticRegression(penalty='l2', C  = 10.0, solver='newton-cg'))\n",
    "])\n",
    "# Time and score test predictions\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test) [:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train) [:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline LogReg with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"logistic regression with c:10 and PCA 150\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>28.218472</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.74%</td>\n",
       "      <td>74.75%</td>\n",
       "      <td>74.78%</td>\n",
       "      <td>logistic regression with c:10 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2011.980767</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.95%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>77.29%</td>\n",
       "      <td>76.03%</td>\n",
       "      <td>76.31%</td>\n",
       "      <td>logistic regression with c:10000 and full set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pipeline      RunTime   TrainAcc  \\\n",
       "0   Baseline MLPClassifier with 1431 inputs   107.850560     92.09%   \n",
       "1   Baseline MLPClassifier with 1431 inputs    55.136100     91.99%   \n",
       "2   Baseline MLPClassifier with 1431 inputs   114.054762     92.16%   \n",
       "3   Baseline MLPClassifier with 1431 inputs    89.093591     92.12%   \n",
       "4   Baseline MLPClassifier with 1431 inputs   114.665470     92.76%   \n",
       "5   Baseline MLPClassifier with 1431 inputs   118.564886     93.09%   \n",
       "6   Baseline MLPClassifier with 1431 inputs   294.561357     92.00%   \n",
       "7   Baseline MLPClassifier with 1431 inputs   273.255891     92.06%   \n",
       "8          Baseline LogReg with 1431 inputs    29.191555     92.00%   \n",
       "9          Baseline LogReg with 1431 inputs    28.218472     92.00%   \n",
       "10         Baseline LogReg with 1431 inputs  2011.980767     92.06%   \n",
       "\n",
       "      TestAcc ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0      91.81%        91.58%     78.08%     72.89%     73.00%   \n",
       "1      91.94%        91.64%     72.09%     72.59%     72.77%   \n",
       "2      91.61%        91.35%     79.37%     73.33%     73.60%   \n",
       "3      86.99%        86.44%     78.87%     65.77%     65.59%   \n",
       "4      89.84%        89.61%     86.30%     68.73%     69.08%   \n",
       "5      89.20%        89.01%     88.04%     68.68%     69.90%   \n",
       "6      91.91%        91.67%     74.56%     74.84%     74.84%   \n",
       "7      91.94%        91.65%     77.34%     75.76%     75.92%   \n",
       "8      91.92%        91.68%     74.79%     74.86%     74.79%   \n",
       "9      91.91%        91.67%     74.74%     74.75%     74.78%   \n",
       "10     91.95%        91.64%     77.29%     76.03%     76.31%   \n",
       "\n",
       "                                      Description  \n",
       "0             MLPClassifier pipeline with K = 200  \n",
       "1             MLPClassifier pipeline with K = 100  \n",
       "2            MLPClassifier pipeline with  K = 300  \n",
       "3         MLPClassifier pipeline with PCA 50 comp  \n",
       "4        MLPClassifier pipeline with PCA 150 comp  \n",
       "5     MLPClassifier pipeline with PCA of 250 comp  \n",
       "6          MLPClass pipeline full data, log, relu  \n",
       "7        MLPClass pipeline full data, relu, lbfgs  \n",
       "8    logistic regression with c:10000 and PCA 150  \n",
       "9       logistic regression with c:10 and PCA 150  \n",
       "10  logistic regression with c:10000 and full set  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('logistic', LogisticRegression(penalty='l2', C  = 10000.0, solver='newton-cg'))\n",
    "])\n",
    "# Time and score test predictions\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test) [:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train) [:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline LogReg with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"logistic regression with c:10000 and full set\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>28.218472</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.74%</td>\n",
       "      <td>74.75%</td>\n",
       "      <td>74.78%</td>\n",
       "      <td>logistic regression with c:10 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2011.980767</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.95%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>77.29%</td>\n",
       "      <td>76.03%</td>\n",
       "      <td>76.31%</td>\n",
       "      <td>logistic regression with c:10000 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2047.943113</td>\n",
       "      <td>92.05%</td>\n",
       "      <td>91.84%</td>\n",
       "      <td>91.59%</td>\n",
       "      <td>77.25%</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>75.96%</td>\n",
       "      <td>logistic regression with c:100 and full set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pipeline      RunTime   TrainAcc  \\\n",
       "0   Baseline MLPClassifier with 1431 inputs   107.850560     92.09%   \n",
       "1   Baseline MLPClassifier with 1431 inputs    55.136100     91.99%   \n",
       "2   Baseline MLPClassifier with 1431 inputs   114.054762     92.16%   \n",
       "3   Baseline MLPClassifier with 1431 inputs    89.093591     92.12%   \n",
       "4   Baseline MLPClassifier with 1431 inputs   114.665470     92.76%   \n",
       "5   Baseline MLPClassifier with 1431 inputs   118.564886     93.09%   \n",
       "6   Baseline MLPClassifier with 1431 inputs   294.561357     92.00%   \n",
       "7   Baseline MLPClassifier with 1431 inputs   273.255891     92.06%   \n",
       "8          Baseline LogReg with 1431 inputs    29.191555     92.00%   \n",
       "9          Baseline LogReg with 1431 inputs    28.218472     92.00%   \n",
       "10         Baseline LogReg with 1431 inputs  2011.980767     92.06%   \n",
       "11         Baseline LogReg with 1431 inputs  2047.943113     92.05%   \n",
       "\n",
       "      TestAcc ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0      91.81%        91.58%     78.08%     72.89%     73.00%   \n",
       "1      91.94%        91.64%     72.09%     72.59%     72.77%   \n",
       "2      91.61%        91.35%     79.37%     73.33%     73.60%   \n",
       "3      86.99%        86.44%     78.87%     65.77%     65.59%   \n",
       "4      89.84%        89.61%     86.30%     68.73%     69.08%   \n",
       "5      89.20%        89.01%     88.04%     68.68%     69.90%   \n",
       "6      91.91%        91.67%     74.56%     74.84%     74.84%   \n",
       "7      91.94%        91.65%     77.34%     75.76%     75.92%   \n",
       "8      91.92%        91.68%     74.79%     74.86%     74.79%   \n",
       "9      91.91%        91.67%     74.74%     74.75%     74.78%   \n",
       "10     91.95%        91.64%     77.29%     76.03%     76.31%   \n",
       "11     91.84%        91.59%     77.25%     75.61%     75.96%   \n",
       "\n",
       "                                      Description  \n",
       "0             MLPClassifier pipeline with K = 200  \n",
       "1             MLPClassifier pipeline with K = 100  \n",
       "2            MLPClassifier pipeline with  K = 300  \n",
       "3         MLPClassifier pipeline with PCA 50 comp  \n",
       "4        MLPClassifier pipeline with PCA 150 comp  \n",
       "5     MLPClassifier pipeline with PCA of 250 comp  \n",
       "6          MLPClass pipeline full data, log, relu  \n",
       "7        MLPClass pipeline full data, relu, lbfgs  \n",
       "8    logistic regression with c:10000 and PCA 150  \n",
       "9       logistic regression with c:10 and PCA 150  \n",
       "10  logistic regression with c:10000 and full set  \n",
       "11    logistic regression with c:100 and full set  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for this experiment let's go with 100 for C, and the full dataset\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', data_pipeline),\n",
    "        ('logistic', LogisticRegression(penalty='l2', C  = 100.0, solver='newton-cg'))\n",
    "])\n",
    "# Time and score test predictions\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test) [:, 1])\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train) [:, 1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\", \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline LogReg with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"logistic regression with c:100 and full set\",]\n",
    "\n",
    "experimentLog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the logistic regression experiments, we see that our best test AUC score so far is using logistic regression, C 100, and the full training dataset. At this point that is the model to beat for our Kaggle submission. Next, we look at multinomial naïve bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIR}/exp_log.pkl', 'wb') as h:\n",
    "    pickle.dump(experimentLog, h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "The objective function for learning a Naive Bayes model can be stated as follows:\n",
    "\n",
    "$$\n",
    "p(x_i \\mid C_k) =  \\frac{(1+ \\sum_{j=1}^m freq(x_{ijk}))}{V + (\\sum_{j=1}^m \\sum_{g=1}^v freq(x_{gjk}))}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column transformer for NB\n",
    "\n",
    "nb_data_pipeline = ColumnTransformer(transformers=[\n",
    "       (\"mnnb_num_pipeline\", MNB_num_pipeline, numerical_at),\n",
    "       (\"cat_pipeline\", BL_cat_pipeline, categorical_at)],\n",
    "       remainder='drop',\n",
    "        n_jobs=1\n",
    "   )\n",
    "\n",
    "X_train_transformed = data_pipeline.fit_transform(X_train)\n",
    "\n",
    "column_names = list(numerical_at) + list(data_pipeline.transformers_[1][1].named_steps[\"ohe\"].get_feature_names(categorical_at))\n",
    "# print(column_names)\n",
    "# display(pd.DataFrame(X_train_transformed,  columns=column_names).head())\n",
    "number_of_inputs = X_train_transformed.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best score: 0.838\n",
      "Best parameters set:\n",
      "\tMNB__alpha: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Test Accuracy\n",
       "0   MNB          0.645"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the pipline in gridsearchcv to find the best params\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('nbpipe',nb_data_pipeline),\n",
    "        ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'MNB__alpha': (0,.01,.1,1,10), #testing for smoothing\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "preds = grid_search.predict_proba(X_train)\n",
    "accuracy = roc_auc_score(y_train, preds[:,1])\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Test Accuracy\"])\n",
    "results.loc[len(results)] = [\"MNB\", np.round(accuracy, 3)]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>28.218472</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.74%</td>\n",
       "      <td>74.75%</td>\n",
       "      <td>74.78%</td>\n",
       "      <td>logistic regression with c:10 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2011.980767</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.95%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>77.29%</td>\n",
       "      <td>76.03%</td>\n",
       "      <td>76.31%</td>\n",
       "      <td>logistic regression with c:10000 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2047.943113</td>\n",
       "      <td>92.05%</td>\n",
       "      <td>91.84%</td>\n",
       "      <td>91.59%</td>\n",
       "      <td>77.25%</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>75.96%</td>\n",
       "      <td>logistic regression with c:100 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baseline MultinomialNB with 1431 inputs</td>\n",
       "      <td>10.547543</td>\n",
       "      <td>86.94%</td>\n",
       "      <td>87.09%</td>\n",
       "      <td>86.82%</td>\n",
       "      <td>63.27%</td>\n",
       "      <td>62.76%</td>\n",
       "      <td>63.29%</td>\n",
       "      <td>multinomial NB pipeline with alpha 1 K=100 fea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pipeline      RunTime   TrainAcc  \\\n",
       "0   Baseline MLPClassifier with 1431 inputs   107.850560     92.09%   \n",
       "1   Baseline MLPClassifier with 1431 inputs    55.136100     91.99%   \n",
       "2   Baseline MLPClassifier with 1431 inputs   114.054762     92.16%   \n",
       "3   Baseline MLPClassifier with 1431 inputs    89.093591     92.12%   \n",
       "4   Baseline MLPClassifier with 1431 inputs   114.665470     92.76%   \n",
       "5   Baseline MLPClassifier with 1431 inputs   118.564886     93.09%   \n",
       "6   Baseline MLPClassifier with 1431 inputs   294.561357     92.00%   \n",
       "7   Baseline MLPClassifier with 1431 inputs   273.255891     92.06%   \n",
       "8          Baseline LogReg with 1431 inputs    29.191555     92.00%   \n",
       "9          Baseline LogReg with 1431 inputs    28.218472     92.00%   \n",
       "10         Baseline LogReg with 1431 inputs  2011.980767     92.06%   \n",
       "11         Baseline LogReg with 1431 inputs  2047.943113     92.05%   \n",
       "12  Baseline MultinomialNB with 1431 inputs    10.547543     86.94%   \n",
       "\n",
       "      TestAcc ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0      91.81%        91.58%     78.08%     72.89%     73.00%   \n",
       "1      91.94%        91.64%     72.09%     72.59%     72.77%   \n",
       "2      91.61%        91.35%     79.37%     73.33%     73.60%   \n",
       "3      86.99%        86.44%     78.87%     65.77%     65.59%   \n",
       "4      89.84%        89.61%     86.30%     68.73%     69.08%   \n",
       "5      89.20%        89.01%     88.04%     68.68%     69.90%   \n",
       "6      91.91%        91.67%     74.56%     74.84%     74.84%   \n",
       "7      91.94%        91.65%     77.34%     75.76%     75.92%   \n",
       "8      91.92%        91.68%     74.79%     74.86%     74.79%   \n",
       "9      91.91%        91.67%     74.74%     74.75%     74.78%   \n",
       "10     91.95%        91.64%     77.29%     76.03%     76.31%   \n",
       "11     91.84%        91.59%     77.25%     75.61%     75.96%   \n",
       "12     87.09%        86.82%     63.27%     62.76%     63.29%   \n",
       "\n",
       "                                          Description  \n",
       "0                 MLPClassifier pipeline with K = 200  \n",
       "1                 MLPClassifier pipeline with K = 100  \n",
       "2                MLPClassifier pipeline with  K = 300  \n",
       "3             MLPClassifier pipeline with PCA 50 comp  \n",
       "4            MLPClassifier pipeline with PCA 150 comp  \n",
       "5         MLPClassifier pipeline with PCA of 250 comp  \n",
       "6              MLPClass pipeline full data, log, relu  \n",
       "7            MLPClass pipeline full data, relu, lbfgs  \n",
       "8        logistic regression with c:10000 and PCA 150  \n",
       "9           logistic regression with c:10 and PCA 150  \n",
       "10      logistic regression with c:10000 and full set  \n",
       "11        logistic regression with c:100 and full set  \n",
       "12  multinomial NB pipeline with alpha 1 K=100 fea...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets go with alpha 1 and select k best 100\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', nb_data_pipeline),\n",
    "        ('feat_sel', SelectKBest(chi2, k=100)),\n",
    "        ('MNB', MultinomialNB(alpha=1))\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:,1])\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:,1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\" , \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MultinomialNB with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"multinomial NB pipeline with alpha 1 K=100 features\",]\n",
    "\n",
    "experimentLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>28.218472</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.74%</td>\n",
       "      <td>74.75%</td>\n",
       "      <td>74.78%</td>\n",
       "      <td>logistic regression with c:10 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2011.980767</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.95%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>77.29%</td>\n",
       "      <td>76.03%</td>\n",
       "      <td>76.31%</td>\n",
       "      <td>logistic regression with c:10000 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2047.943113</td>\n",
       "      <td>92.05%</td>\n",
       "      <td>91.84%</td>\n",
       "      <td>91.59%</td>\n",
       "      <td>77.25%</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>75.96%</td>\n",
       "      <td>logistic regression with c:100 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baseline MultinomialNB with 1431 inputs</td>\n",
       "      <td>10.547543</td>\n",
       "      <td>86.94%</td>\n",
       "      <td>87.09%</td>\n",
       "      <td>86.82%</td>\n",
       "      <td>63.27%</td>\n",
       "      <td>62.76%</td>\n",
       "      <td>63.29%</td>\n",
       "      <td>multinomial NB pipeline with alpha 1 K=100 fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baseline MultinomialNB with 1431 inputs</td>\n",
       "      <td>9.503950</td>\n",
       "      <td>83.91%</td>\n",
       "      <td>84.14%</td>\n",
       "      <td>83.98%</td>\n",
       "      <td>64.45%</td>\n",
       "      <td>64.10%</td>\n",
       "      <td>64.52%</td>\n",
       "      <td>multinomial NB pipeline with alpha 10 and full...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pipeline      RunTime   TrainAcc  \\\n",
       "0   Baseline MLPClassifier with 1431 inputs   107.850560     92.09%   \n",
       "1   Baseline MLPClassifier with 1431 inputs    55.136100     91.99%   \n",
       "2   Baseline MLPClassifier with 1431 inputs   114.054762     92.16%   \n",
       "3   Baseline MLPClassifier with 1431 inputs    89.093591     92.12%   \n",
       "4   Baseline MLPClassifier with 1431 inputs   114.665470     92.76%   \n",
       "5   Baseline MLPClassifier with 1431 inputs   118.564886     93.09%   \n",
       "6   Baseline MLPClassifier with 1431 inputs   294.561357     92.00%   \n",
       "7   Baseline MLPClassifier with 1431 inputs   273.255891     92.06%   \n",
       "8          Baseline LogReg with 1431 inputs    29.191555     92.00%   \n",
       "9          Baseline LogReg with 1431 inputs    28.218472     92.00%   \n",
       "10         Baseline LogReg with 1431 inputs  2011.980767     92.06%   \n",
       "11         Baseline LogReg with 1431 inputs  2047.943113     92.05%   \n",
       "12  Baseline MultinomialNB with 1431 inputs    10.547543     86.94%   \n",
       "13  Baseline MultinomialNB with 1431 inputs     9.503950     83.91%   \n",
       "\n",
       "      TestAcc ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0      91.81%        91.58%     78.08%     72.89%     73.00%   \n",
       "1      91.94%        91.64%     72.09%     72.59%     72.77%   \n",
       "2      91.61%        91.35%     79.37%     73.33%     73.60%   \n",
       "3      86.99%        86.44%     78.87%     65.77%     65.59%   \n",
       "4      89.84%        89.61%     86.30%     68.73%     69.08%   \n",
       "5      89.20%        89.01%     88.04%     68.68%     69.90%   \n",
       "6      91.91%        91.67%     74.56%     74.84%     74.84%   \n",
       "7      91.94%        91.65%     77.34%     75.76%     75.92%   \n",
       "8      91.92%        91.68%     74.79%     74.86%     74.79%   \n",
       "9      91.91%        91.67%     74.74%     74.75%     74.78%   \n",
       "10     91.95%        91.64%     77.29%     76.03%     76.31%   \n",
       "11     91.84%        91.59%     77.25%     75.61%     75.96%   \n",
       "12     87.09%        86.82%     63.27%     62.76%     63.29%   \n",
       "13     84.14%        83.98%     64.45%     64.10%     64.52%   \n",
       "\n",
       "                                          Description  \n",
       "0                 MLPClassifier pipeline with K = 200  \n",
       "1                 MLPClassifier pipeline with K = 100  \n",
       "2                MLPClassifier pipeline with  K = 300  \n",
       "3             MLPClassifier pipeline with PCA 50 comp  \n",
       "4            MLPClassifier pipeline with PCA 150 comp  \n",
       "5         MLPClassifier pipeline with PCA of 250 comp  \n",
       "6              MLPClass pipeline full data, log, relu  \n",
       "7            MLPClass pipeline full data, relu, lbfgs  \n",
       "8        logistic regression with c:10000 and PCA 150  \n",
       "9           logistic regression with c:10 and PCA 150  \n",
       "10      logistic regression with c:10000 and full set  \n",
       "11        logistic regression with c:100 and full set  \n",
       "12  multinomial NB pipeline with alpha 1 K=100 fea...  \n",
       "13  multinomial NB pipeline with alpha 10 and full...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets go with alpha 1 and full dataset\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', nb_data_pipeline),\n",
    "        ('MNB', MultinomialNB(alpha=1))\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:,1])\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:,1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\" , \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MultinomialNB with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"multinomial NB pipeline with alpha 1 and full set\",]\n",
    "\n",
    "experimentLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>TrainAcc</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>ValidationAcc</th>\n",
       "      <th>Train_Auc</th>\n",
       "      <th>Test_Auc</th>\n",
       "      <th>Valid_Auc</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>107.850560</td>\n",
       "      <td>92.09%</td>\n",
       "      <td>91.81%</td>\n",
       "      <td>91.58%</td>\n",
       "      <td>78.08%</td>\n",
       "      <td>72.89%</td>\n",
       "      <td>73.00%</td>\n",
       "      <td>MLPClassifier pipeline with K = 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>55.136100</td>\n",
       "      <td>91.99%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>72.59%</td>\n",
       "      <td>72.77%</td>\n",
       "      <td>MLPClassifier pipeline with K = 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.054762</td>\n",
       "      <td>92.16%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>91.35%</td>\n",
       "      <td>79.37%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>73.60%</td>\n",
       "      <td>MLPClassifier pipeline with  K = 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>89.093591</td>\n",
       "      <td>92.12%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>86.44%</td>\n",
       "      <td>78.87%</td>\n",
       "      <td>65.77%</td>\n",
       "      <td>65.59%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 50 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>114.665470</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>89.61%</td>\n",
       "      <td>86.30%</td>\n",
       "      <td>68.73%</td>\n",
       "      <td>69.08%</td>\n",
       "      <td>MLPClassifier pipeline with PCA 150 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>118.564886</td>\n",
       "      <td>93.09%</td>\n",
       "      <td>89.20%</td>\n",
       "      <td>89.01%</td>\n",
       "      <td>88.04%</td>\n",
       "      <td>68.68%</td>\n",
       "      <td>69.90%</td>\n",
       "      <td>MLPClassifier pipeline with PCA of 250 comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>294.561357</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.56%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>MLPClass pipeline full data, log, relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline MLPClassifier with 1431 inputs</td>\n",
       "      <td>273.255891</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.94%</td>\n",
       "      <td>91.65%</td>\n",
       "      <td>77.34%</td>\n",
       "      <td>75.76%</td>\n",
       "      <td>75.92%</td>\n",
       "      <td>MLPClass pipeline full data, relu, lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>29.191555</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.92%</td>\n",
       "      <td>91.68%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>74.86%</td>\n",
       "      <td>74.79%</td>\n",
       "      <td>logistic regression with c:10000 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>28.218472</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>91.91%</td>\n",
       "      <td>91.67%</td>\n",
       "      <td>74.74%</td>\n",
       "      <td>74.75%</td>\n",
       "      <td>74.78%</td>\n",
       "      <td>logistic regression with c:10 and PCA 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2011.980767</td>\n",
       "      <td>92.06%</td>\n",
       "      <td>91.95%</td>\n",
       "      <td>91.64%</td>\n",
       "      <td>77.29%</td>\n",
       "      <td>76.03%</td>\n",
       "      <td>76.31%</td>\n",
       "      <td>logistic regression with c:10000 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baseline LogReg with 1431 inputs</td>\n",
       "      <td>2047.943113</td>\n",
       "      <td>92.05%</td>\n",
       "      <td>91.84%</td>\n",
       "      <td>91.59%</td>\n",
       "      <td>77.25%</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>75.96%</td>\n",
       "      <td>logistic regression with c:100 and full set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baseline MultinomialNB with 1431 inputs</td>\n",
       "      <td>10.547543</td>\n",
       "      <td>86.94%</td>\n",
       "      <td>87.09%</td>\n",
       "      <td>86.82%</td>\n",
       "      <td>63.27%</td>\n",
       "      <td>62.76%</td>\n",
       "      <td>63.29%</td>\n",
       "      <td>multinomial NB pipeline with alpha 1 K=100 fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baseline MultinomialNB with 1431 inputs</td>\n",
       "      <td>9.503950</td>\n",
       "      <td>83.91%</td>\n",
       "      <td>84.14%</td>\n",
       "      <td>83.98%</td>\n",
       "      <td>64.45%</td>\n",
       "      <td>64.10%</td>\n",
       "      <td>64.52%</td>\n",
       "      <td>multinomial NB pipeline with alpha 10 and full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baseline MultinomialNB with 1431 inputs</td>\n",
       "      <td>9.411838</td>\n",
       "      <td>84.29%</td>\n",
       "      <td>84.46%</td>\n",
       "      <td>84.22%</td>\n",
       "      <td>64.29%</td>\n",
       "      <td>63.91%</td>\n",
       "      <td>64.35%</td>\n",
       "      <td>multinomial NB pipeline with alpha 1 and full set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pipeline      RunTime   TrainAcc  \\\n",
       "0   Baseline MLPClassifier with 1431 inputs   107.850560     92.09%   \n",
       "1   Baseline MLPClassifier with 1431 inputs    55.136100     91.99%   \n",
       "2   Baseline MLPClassifier with 1431 inputs   114.054762     92.16%   \n",
       "3   Baseline MLPClassifier with 1431 inputs    89.093591     92.12%   \n",
       "4   Baseline MLPClassifier with 1431 inputs   114.665470     92.76%   \n",
       "5   Baseline MLPClassifier with 1431 inputs   118.564886     93.09%   \n",
       "6   Baseline MLPClassifier with 1431 inputs   294.561357     92.00%   \n",
       "7   Baseline MLPClassifier with 1431 inputs   273.255891     92.06%   \n",
       "8          Baseline LogReg with 1431 inputs    29.191555     92.00%   \n",
       "9          Baseline LogReg with 1431 inputs    28.218472     92.00%   \n",
       "10         Baseline LogReg with 1431 inputs  2011.980767     92.06%   \n",
       "11         Baseline LogReg with 1431 inputs  2047.943113     92.05%   \n",
       "12  Baseline MultinomialNB with 1431 inputs    10.547543     86.94%   \n",
       "13  Baseline MultinomialNB with 1431 inputs     9.503950     83.91%   \n",
       "14  Baseline MultinomialNB with 1431 inputs     9.411838     84.29%   \n",
       "\n",
       "      TestAcc ValidationAcc  Train_Auc   Test_Auc  Valid_Auc  \\\n",
       "0      91.81%        91.58%     78.08%     72.89%     73.00%   \n",
       "1      91.94%        91.64%     72.09%     72.59%     72.77%   \n",
       "2      91.61%        91.35%     79.37%     73.33%     73.60%   \n",
       "3      86.99%        86.44%     78.87%     65.77%     65.59%   \n",
       "4      89.84%        89.61%     86.30%     68.73%     69.08%   \n",
       "5      89.20%        89.01%     88.04%     68.68%     69.90%   \n",
       "6      91.91%        91.67%     74.56%     74.84%     74.84%   \n",
       "7      91.94%        91.65%     77.34%     75.76%     75.92%   \n",
       "8      91.92%        91.68%     74.79%     74.86%     74.79%   \n",
       "9      91.91%        91.67%     74.74%     74.75%     74.78%   \n",
       "10     91.95%        91.64%     77.29%     76.03%     76.31%   \n",
       "11     91.84%        91.59%     77.25%     75.61%     75.96%   \n",
       "12     87.09%        86.82%     63.27%     62.76%     63.29%   \n",
       "13     84.14%        83.98%     64.45%     64.10%     64.52%   \n",
       "14     84.46%        84.22%     64.29%     63.91%     64.35%   \n",
       "\n",
       "                                          Description  \n",
       "0                 MLPClassifier pipeline with K = 200  \n",
       "1                 MLPClassifier pipeline with K = 100  \n",
       "2                MLPClassifier pipeline with  K = 300  \n",
       "3             MLPClassifier pipeline with PCA 50 comp  \n",
       "4            MLPClassifier pipeline with PCA 150 comp  \n",
       "5         MLPClassifier pipeline with PCA of 250 comp  \n",
       "6              MLPClass pipeline full data, log, relu  \n",
       "7            MLPClass pipeline full data, relu, lbfgs  \n",
       "8        logistic regression with c:10000 and PCA 150  \n",
       "9           logistic regression with c:10 and PCA 150  \n",
       "10      logistic regression with c:10000 and full set  \n",
       "11        logistic regression with c:100 and full set  \n",
       "12  multinomial NB pipeline with alpha 1 K=100 fea...  \n",
       "13  multinomial NB pipeline with alpha 10 and full...  \n",
       "14  multinomial NB pipeline with alpha 1 and full set  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets go with alpha 10 and full dataset\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('dpipe', nb_data_pipeline),\n",
    "        ('MNB', MultinomialNB(alpha=10))\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "run_time = (time() - t0)\n",
    "\n",
    "trainAcc  = pipeline.score(X_train, y_train)\n",
    "validAcc  = pipeline.score(X_valid, y_valid)\n",
    "testAcc  = pipeline.score(X_test, y_test)\n",
    "train_Auc = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:,1])\n",
    "test_Auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:,1])\n",
    "valid_Auc = roc_auc_score(y_valid, pipeline.predict_proba(X_valid)[:,1])\n",
    "\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[\"Pipeline\", \"RunTime\" , \"TrainAcc\", \"TestAcc\",\"ValidationAcc\", \n",
    "                                               \"Train_Auc\", \"Test_Auc\", \"Valid_Auc\",\"Description\",])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"Baseline MultinomialNB with {number_of_inputs} inputs\", run_time,\n",
    "                                        f\"{trainAcc*100:8.2f}%\",f\"{testAcc*100:8.2f}%\",f\"{validAcc*100:8.2f}%\",\n",
    "                                        f\"{train_Auc*100:8.2f}%\",f\"{test_Auc*100:8.2f}%\",f\"{valid_Auc*100:8.2f}%\", \"multinomial NB pipeline with alpha 1 and full set\",]\n",
    "\n",
    "experimentLog\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Description** After running all the experiments it appears that our best result is logistic regression with c:10000 and full set. Multilayer perceptron also preduced close accuracy numbers to our best. Also important to note that our best result logistic regression with the full dataset took about 34 minutes on the test machine while the previuos experiment using primary component analysis acheived a test auc only 1.28 lower but that only took 33 seconds on the test machine so this is certainly a much faster way to get similar accuracy with this data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![submission.png]( data:image/png;base64,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)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion Part 3__\n",
    "\n",
    "Above we see how small changes to the machine learning algorithm and hyperparameters can have an impact on the ability to make a classification prediction about unkown data. The end result is that we are able to correctly predict default about 74 percent of the time which is certainly of value to achieve this business objective. Some additional improvements that can be made in future parts to this project include using different machine learning systems such as PyTorch or SparkML in order to test different approaches. Also we should work on balancing the dataset since we know that this dataset contains far more of the majority than the minority class. Additionally we could look at our column transformation process and pre-process the data in differnt ways, or we could look at creating a multiclass dataset to offer more granularity in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82818b14de67220291b5b43de7f72d0e85f2ba15f2bafdeb51a5520bc5ee5ebe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
